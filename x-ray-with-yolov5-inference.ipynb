{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfrom os import listdir, makedirs, symlink, chdir\nfrom os.path import isfile, join\n\nfrom shutil import copyfile, rmtree\n\nfrom IPython.display import Image, clear_output  # to display images\nclear_output()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup YOLOv5","metadata":{}},{"cell_type":"code","source":"if not os.path.exists('/kaggle/working/yolov5/'):\n    !git clone https://github.com/ultralytics/yolov5  # clone repo\n    chdir('yolov5')\n    !pip install pycocotools -qr requirements.txt  # install dependencies\n    !pip uninstall -y wandb  # open wandb bugs \n\n    import torch\n    print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup directories","metadata":{}},{"cell_type":"code","source":"# Input data is generated in my other notebook x-ray-with-yolov5-data-setup\n\ntest_path = '/kaggle/input/x-ray-with-yolov5-test-setup'\ntraining_weights_path = '/kaggle/input/yolov5xrayrunsweights' # generated with X-ray_with_YoloV5 (training)\norig_dicom_files = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/test'\n\nworking_path = '/kaggle/working'\ndata_path = join(working_path,'data')\nimages_path = join(data_path,'images')\nin_images_path = join(test_path,'test_images')\noutput_path = join(working_path,'output')\n\n\n# Working paths for yolov5\nyolo_path = join(working_path,'yolov5')\nyolo_runs = join(yolo_path,'runs')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup images directory with links to images","metadata":{}},{"cell_type":"code","source":"makedirs(images_path, exist_ok = True)\n\nif len(listdir(in_images_path)) > len(listdir(images_path)):\n    for img_file in listdir(in_images_path):\n        if img_file.endswith('.jpg'):\n            symlink(join(in_images_path,img_file), join(images_path,img_file))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup weights from training execution\nTraining was done in [https://www.kaggle.com/amirsher/x-ray-with-yolov5-training/](https://www.kaggle.com/amirsher/x-ray-with-yolov5-training/)","metadata":{}},{"cell_type":"code","source":"# copy the weight file created in training\nbest_weights = 'best.pt'\ncopyfile(join(training_weights_path,best_weights), join(yolo_path,best_weights))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CSV of submission test images with original image sizes\n\ncsv_file = join(test_path,'sample_submission.csv')\nsub_csv_df = pd.read_csv(csv_file)\nsub_csv_df.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"# Output paths for YOLO results\nproject = 'xray'\ndetect_path = join(yolo_path,project,'exp') # image results\nlabels_path = join(detect_path,'labels') # labels *.txt results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Clear previous results\nrmtree(detect_path, ignore_errors=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chdir(yolo_path)\n\nconf = 0.01\n\n!python detect.py --weights $best_weights --img 512 --conf $conf --source $images_path --save-txt --save-conf --project $project --exist-ok\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define Dicom_image class to examine outputs","metadata":{}},{"cell_type":"code","source":"# import packages for dicom image\nimport cv2\nimport matplotlib\nimport imgaug as ia\nfrom imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\nfrom imgaug import augmenters as iaa\nfrom matplotlib import colors\nimport random\nimport pydicom as dicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom os.path import join, exists\n\n\n# Define dicom_image class for displaying dicom image files with detections (removed unnecessary functions from my original class)\nclass Dicom_image:\n    def __init__(self, path, image_name, classes=[]):\n        '''\n        Import image\n        :param path: Path to the image\n        :param image_name: image name\n        '''\n        self.path = path\n        if image_name.endswith('.dicom'):\n            self.file_name = image_name\n            self.image_name = image_name[:-6]\n        else:\n            self.file_name = image_name + '.dicom'\n            self.image_name = image_name\n        self.file_path = join(self.path, self.file_name)\n        if exists(self.file_path):\n            self.dicom_file = dicom.dcmread(self.file_path)\n            self.image_orig = self.read_xray()\n            self.orig_size = (self.image_orig.shape[0],self.image_orig.shape[1]) # Original image size before resizing - (h,w)\n            self.bbs = [] # Initial bounding boxes\n            self.classes = classes\n            self.image_aug = None # Augmented image\n            self.bbs_aug = []  # bounding boxes after augmentation\n            self.image_resize = None # image after resize\n            self.bbs_resize= [] # bounding boxes after resize\n        else:\n            print (f\"Error! {self.file_path} does not exists!\")\n    \n    def read_xray(self, voi_lut = True, fix_monochrome = True):\n        '''\n        Read image data from the dicom file\n        (reference: https://www.kaggle.com/raddar/vinbigdata-competition-jpg-data-2x-downsampled)\n        '''\n        data_file = self.dicom_file\n        # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n        if voi_lut:\n            data = apply_voi_lut(data_file.pixel_array, data_file)\n        else:\n            data = data_file.pixel_array\n\n        # depending on this value, X-ray may look inverted - fix that:\n        if fix_monochrome and data_file.PhotometricInterpretation == \"MONOCHROME1\":\n            data = np.amax(data) - data\n        data = data - np.min(data)\n        data = data / np.max(data)\n        data = (data * 255.0).astype(np.uint8)\n        # Use CLAHE (Contrast Limited Adaptive Histogram Equalization) to improve contrast\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n        data = clahe.apply(data)\n        data = cv2.cvtColor(data,cv2.COLOR_GRAY2RGB) # convert to 3 channel grayscale\n        return data\n\n    def add_bbox(self, xmin, ymin, xmax, ymax, cl_label):\n        '''\n        Add a bounding box to list of bounding boxes in the image\n        :param xmin, ymin, xmax, ymax: bounding box coordinates\n        :param cl_label: string label class of the bounding box\n        '''\n        self.bbs.append(BoundingBox(x1=xmin, y1=ymin, x2=xmax, y2=ymax, label=cl_label))\n    \n    def add_bbox_from_df(self, df):\n        '''\n        Add bounding boxes to the list of bounding boxes from a pandas dataframe\n        :param df: dataframe that contains bounding boxes and image_id with the same self.image_name\n        '''\n        image_df = df[df['image_id']==self.image_name]\n        for i, row in image_df.iterrows():\n            self.add_bbox(row.x_min, row.y_min ,row.x_max, row.y_max,str(row.cl))\n\n    def clear_bbs(self):\n        '''\n        Remove all bounding boxes from the list of bounding boxes\n        '''\n        self.bbs = []\n    \n    \n    def resize (self, img=None, bounding_boxes=None, downscale_factor = 1, max_dim = None):\n        '''\n        Resize image\n        :param downscale_factor: downscale factor (default = 1)\n        :param max_dim: downscale so that largest dimension (height or width) is equal max_dim. The other dimension reduced proportionately.\n        '''\n        img = self.image_orig if img is None else img\n        img_size = (img.shape[0], img.shape[1])\n        bounding_boxes = self.bbs if bounding_boxes is None else bounding_boxes\n        if type(bounding_boxes)==BoundingBoxesOnImage:\n            bbs = bounding_boxes\n        else:\n            bbs = BoundingBoxesOnImage(bounding_boxes, shape=img.shape)\n        \n        if downscale_factor > 1:  # Resize by a constant factor\n            new_shape = tuple([int(x / downscale_factor) for x in img_size])       \n        elif max_dim != None: # Resize so that maximum length (width or height) will be max_dim. The other dimension resized proportionately\n            downscale_factor =  max(img.shape) / max_dim\n            new_shape = tuple([round(x / downscale_factor) for x in img_size])\n        else:\n            new_shape = img_size # Don't resize\n\n        self.image_resize = ia.imresize_single_image(img, new_shape)\n        self.bbs_resize = bbs.on(self.image_resize)\n        return self.image_resize, self.bbs_resize\n    \n    def parse_label(self, bb):\n        '''\n        Convert label index to label class name and color\n        :param bb: bounding box with label\n        '''\n        color_pallete = ['lightcoral','brown','red','darksalmon','chocolate',\n                  'darkorange','darkgoldenrod','gold','olive','yellow',\n                  'green','lime','blue','darkorchid']\n        try:\n            class_code = int(bb.label)\n            class_name = self.classes[class_code]\n        except:\n            class_code = random.randrange(len(colors)) # if class nunber was not specified, or label was not an index to class\n            class_name = ''\n        cl_color = tuple(np.array(colors.to_rgb(color_pallete[class_code]))*255)\n        return cl_color, class_name\n    \n    def show_image(self, img=None, bounding_boxes=None, showbbs=True, showlabel=True):\n        '''\n        Show the image with bounding boxes\n        :param img: image to be processed\n        :param bounding_boxes: list of bounding boxes\n        :param showbbs: flag to show the bounding boxes, if there are any (default=True)\n        :param showlabel: flag to show the labels of the bounding boxes, if there are any (default=True)\n        '''\n        img = self.image_orig if img is None else img\n        bounding_boxes = self.bbs if bounding_boxes is None else bounding_boxes\n        bbs=[]\n        if bounding_boxes != []:\n            if type(bounding_boxes)==BoundingBoxesOnImage:\n                bbs = bounding_boxes.bounding_boxes\n            else:\n                bbs = bounding_boxes\n            \n            for bb in bbs:\n                bbox_color, bbox_label = self.parse_label(bb)\n                if showlabel:\n                    bbl = bb.copy(label=bbox_label) # replace label from class nunber to class name\n                    img = bbl.draw_on_image(image=img, color=bbox_color)\n                elif showbbs:\n                    img = bb.draw_box_on_image(image=img, color=bbox_color)  # only draw box without label   \n        ia.imshow(img)\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display xray image from dicom with bounding boxes that are attached to the image\n\nclasses = ['Aortic enlargement','Atelectasis','Calcification','Cardiomegaly','Consolidation','ILD','Infiltration','Lung Opacity','Nodule/Mass','Other lesion','Pleural effusion','Pleural thickening','Pneumothorax','Pulmonary fibrosis']\n\ndef show_dicom(fpath, image_id, df):\n    dic = Dicom_image(path=fpath, image_name=image_id, classes=classes)\n    dic.add_bbox_from_df(df)\n    dic.resize(max_dim=700)\n    dic.show_image(img=dic.image_resize, bounding_boxes=dic.bbs_resize, showlabel=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Process detection output files","metadata":{}},{"cell_type":"code","source":"# Get detections from txt files into a DataFrame\n\nnum_detections = 0\nnum_detected_files = 0\nmy_columns = ['image_id','cl','prob','x_min','y_min','x_max','y_max','rel_cx','rel_cy','rel_h','rel_w','rel_area']\ndetect_df = pd.DataFrame([], columns=my_columns)\n\nfor txt_file in listdir(labels_path):\n        if txt_file.endswith('.txt'):\n            num_detected_files += 1\n            image_id = txt_file[:-4]\n            df = sub_csv_df.loc[sub_csv_df['image_id']==image_id]  # locate image in submission dataframe\n            image_h = int(df['image_h'])\n            image_w = int(df['image_w'])\n            file1 = open(join(labels_path, txt_file), 'r') \n            Lines = file1.readlines()\n            \n            for line in Lines:\n                (cl,cx,cy,w,h,prob) = line.split()\n                bbox_w = float(w)*image_w\n                bbox_h = float(h)*image_h\n                bbox_cx = float(cx)*image_w\n                bbox_cy = float(cy)*image_h\n                x_min = int(bbox_cx - bbox_w/2)\n                x_max = int(bbox_cx + bbox_w/2)\n                y_min = int(bbox_cy - bbox_h/2)\n                y_max = int(bbox_cy + bbox_h/2)\n                prob_round = round(float(prob), 1)\n                rel_h, rel_w = round(float(h),3), round(float(w),3)\n                rel_cx, rel_cy = round(float(cx),2), round(float(cy),2)\n                rel_area = round(rel_h*rel_w,4)\n                num_detections += 1\n                df_row = pd.DataFrame([[image_id,cl,prob_round,x_min,y_min,x_max,y_max,rel_cx,rel_cy,rel_h,rel_w,rel_area]], columns=my_columns)\n                detect_df = detect_df.append(df_row)\n            ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print (f'Using confidence threshold of {conf}:')\nprint (f'Found {num_detections} detections in {num_detected_files} files.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sort detections by probability\ndetect_df.sort_values(by=['image_id', 'prob'], inplace=True)\ndetect_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Examine the output and clean some errors","metadata":{}},{"cell_type":"code","source":"%%script echo skipping\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(20,10)})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script echo skipping\n!pip install matplotlib==3.1.3  # workaround a bug in matplotlib that happen sometimes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script echo skipping\n# Check for each class - x,y scatter; area histogram. Look for anormalities.\n\ncheck_class = 13\ndetect_df_filt = detect_df[detect_df['cl']==str(check_class)]\nprint (f'showing class {check_class} = {classes[check_class]}')\nprint ('Number of detections:', len(detect_df_filt))\n\nsns.scatterplot(data=detect_df_filt, x=\"rel_cx\", y=\"rel_cy\", hue=\"cl\", size=\"prob\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script echo skipping\nsns.distplot(a=detect_df_filt['rel_area'],norm_hist=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script echo skipping\nsns.displot(data=detect_df_filt, x=\"rel_cx\", y=\"rel_cy\", kind=\"kde\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script echo skipping\nexamine_df = detect_df_filt[detect_df_filt['rel_area']>0.10]\nprint ('Num cases = ', len(examine_df))\nexamine_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script echo skipping\nshow_dicom(orig_dicom_files,'19c44a83a0b26af42aefbcbf7b9f9380', detect_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Remove possible errors (by statistics and examinations)\nCreate filters according to the above findings","metadata":{}},{"cell_type":"code","source":"# err_filter1 = ~((detect_df['cl']=='1') & (detect_df['rel_area']<0.02))\n# err_filter2 = ~((detect_df['cl']=='6') & (detect_df['rel_cy']>0.7))\n# err_filter3 = ~((detect_df['cl']=='8') & (detect_df['rel_area']>0.01))\n# err_filter4 = ~((detect_df['cl']=='11') & (detect_df['rel_area']>0.07))\n\n# error_filter = err_filter1 & err_filter2 & err_filter3 & err_filter4\n\nreduced_cols = ['image_id','cl','prob','x_min','y_min','x_max','y_max']\n# reduced_df = detect_df[error_filter][reduced_cols]\nreduced_df = detect_df[reduced_cols]\nreduced_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_final = len(reduced_df)\nnum_detections = len(detect_df)\nprint (f'Total detections:{num_detections}. Total removed:{num_detections-num_final}. Detections left:{num_final}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create submission\n\ndefault_detect = '14 1 0 0 1 1'\n\nfor index, row in reduced_df.iterrows():\n    detection = '%s %.1f %d %d %d %d'% tuple(row.values[1:])\n    df = sub_csv_df.loc[sub_csv_df['image_id']==row.image_id]\n    if default_detect in sub_csv_df.loc[df.index.item(),'PredictionString']: # remove default \n        sub_csv_df.loc[df.index,'PredictionString'] = detection # first detection\n    else:\n        sub_csv_df.loc[df.index,'PredictionString'] += ' ' + detection # add detections\n        \n\nsubmission_df = sub_csv_df.drop(['image_h', 'image_w'], axis=1)\nsubmission_df.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chdir(working_path)\nmakedirs(output_path, exist_ok = True)\nsubmit_file = join(output_path,'submission.csv')\nsubmission_df.to_csv(submit_file, index=False)\nprint ('created file ', submit_file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove files that hide the submission output\nrmtree(yolo_path, ignore_errors=True)\nrmtree(data_path, ignore_errors=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}