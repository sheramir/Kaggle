{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":25914,"databundleVersionId":2227051,"sourceType":"competition"},{"sourceId":2204662,"sourceType":"datasetVersion","datasetId":1324001},{"sourceId":2209036,"sourceType":"datasetVersion","datasetId":1326631}],"dockerImageVersionId":30096,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Readability Regressor","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport joblib\nimport os\nfrom pathlib import Path\nimport sys\n\nfrom sklearn.metrics import mean_squared_error","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define Files and Directories","metadata":{}},{"cell_type":"code","source":"# Input files\ndata_dir = Path('../input/commonlitreadabilityprize')\ntrain_file = data_dir / 'train.csv'\ntest_file = data_dir / 'test.csv'\nsample_file = data_dir / 'sample_submission.csv'\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data files for readability formulas\ndalechall_file = '../input/the-new-dalechall-familiar-words-list/DaleChallEasyWordList.txt'\nspache_file = '../input/spache-familiar-words-list/SpacheFamiliarWordList.txt'\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(train_file, index_col='id')\ntest_df = pd.read_csv(test_file, index_col='id')\nprint(f'Train size:{train_df.shape}. Test size:{test_df.shape}')\ntrain_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Calculate Classic Metrics for Readability\nBased on:\n\nhttps://clickhelp.com/software-documentation-tool/user-manual/readability-metrics.html\n\nhttps://readabilityformulas.com/\n\n### Common Classic Metrics:\nMost readability formulas (**Fry, Flesch-Kincaid, Gunning Fog, and others**) are based on weighted combination of:\n- ASL: Average sentence length (number of words in a sentence, excluding numbers).\n- ASW: Average number of syllables per word.\n\nSome other formulas (**SMOG, Linsear Write**) are similar to the above, but instead of average word length, they count number of long words (Polysyllables - 3 or more syllables). Some more simple formulas use average characters count per word instead of syllables.\n\n### Formulas based on list of common words:\n\n**The New Dale-Chall Formula** and Spache Readability Formula use a predefined set of \"common\" words and the ratio of \"unfamiliar\" or \"difficult\" words (PDW) and words per sentence (ASL).\n\nDifficult words in Dale-Chall formula are words that do not appear on a specially designed list of common words familiar to most 4th-grade students - around 3000 words (https://readabilityformulas.com/articles/dale-chall-readability-word-list.php).\n\n**The Spache Formula** considers “unfamiliar words” as words that 3rd grade and below do not recognize. The Spache list comprises of 925 familiar words (https://readabilityformulas.com/articles/spache-formula-word-list.php).\n\nThe Spache Formula is best used to calculate the difficulty of text that falls at the 3rd grade level or below, while the New Dale-Chall Formula is best used for texts that falls at the 4th grade level or above.\n\n**Words considering \"familiar\"**:\n\n- Words appearing on the common words list.\n\n- Variants of words appearing on the list that have regular verb form endings – ing, -ed, -es.\n\n- Plural and Possessive endings of nouns from the list.\n\n- First Names.\n\n- Single letters standing alone as words. E.g., ‘C is the third letter of the alphabets.’\n\n**‘Difficult Words’:**\n\n- Words not appearing on the \"familiar\" list or its variants as specified above.\n\n- Variants of words appearing on the list that have irregular verb form endings – unless those variant forms also appear on the list.\n\n- Variants of words appearing on the list that have adverbial, comparative, or superlative endings – ly, -er, -est.\n\n- Words not appearing on the list are counted only once, even if they appear later with other endings.\n\n\n**Bottom line Features Extraction:**\n\nWe'll extract the following features from the text:\n\n- ASL: Average Sentence Length.\n- ASW: Average Syllables per Word.\n- ROP: Ratio Of Polysyllables (percentage of 3 or more syllables words in total words)\n- RDC: Ratio of Dale-Chall difficult words\n- ROS: Ratio Of Spache difficult words","metadata":{}},{"cell_type":"code","source":"import spacy\n\ntry:\n    import syllapy\nexcept ImportError as e:\n    !pip install syllapy -q\n    import syllapy\n    \nnlp = spacy.load('en_core_web_sm')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(dalechall_file) as f:\n    dalechall_list = f.read().lower().split()\n    \nwith open(spache_file) as f:\n    spache_list = f.read().lower().split()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ASL: Average Sentence Length.\n# ASW: Average Syllables per Word.\n# ROP: Ratio Of Polysyllables (percentage of 3 or more syllables words in total words)\n# RDC: Ratio of Dale-Chall difficult words\n# ROS: Ratio Of Spache difficult words\n\ndef count_difficult_words (word, easy_words_list, difficult_words_dict):\n    word_lemma = word.lemma_.lower()\n    if (\n        word.ent_type_ != 'PERSON'\n        and word.text.lower() not in easy_words_list\n        and word_lemma not in easy_words_list\n    ):\n        try:\n            difficult_words_dict[word_lemma] += 1\n        except:\n            difficult_words_dict[word_lemma] = 1\n    return difficult_words_dict\n\ndef extract_readability_features(in_df):\n    ASL_list, ASW_list, ROP_list, RDC_list, ROS_list = [], [], [], [], []\n    total_words_list, num_sentences_list = [], []\n    df = in_df.copy()\n    \n    for txt in df.excerpt:    \n        doc = nlp(txt)\n        sents = len(list(doc.sents)) # Number of sentences\n        difficult_words_dale = {}\n        difficult_words_spach = {}\n        word_count = 0\n        syllables_count = 0\n        polysyllables_count = 0\n        for token in doc:\n            if token.is_alpha:\n                word_count += 1\n                syllables = syllapy.count(token.text)\n                syllables_count += syllables\n                if syllables>=3:\n                    polysyllables_count+=1\n                difficult_words_dale = count_difficult_words (token, dalechall_list, difficult_words_dale)\n                difficult_words_spach = count_difficult_words (token, spache_list, difficult_words_spach)\n                \n        ASL_list.append(word_count/sents)\n        ASW_list.append(syllables_count/word_count)\n        ROP_list.append(polysyllables_count/word_count)\n        RDC_list.append(len(difficult_words_dale) / word_count)\n        ROS_list.append(len(difficult_words_spach) / word_count)\n        num_sentences_list.append(sents)\n        total_words_list.append(word_count)\n        \n    df['ASL'] = ASL_list\n    df['ASW'] = ASW_list\n    df['ROP'] = ROP_list\n    df['RDC'] = RDC_list\n    df['ROS'] = ROS_list\n    df['num_sentences'] = num_sentences_list\n    df['total_words'] = total_words_list\n    return df\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df_new = extract_readability_features(train_df)\ntrain_df_new.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df_new = extract_readability_features(test_df)\ntest_df_new.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df_new.sort_values(by=['target']).head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df_new.sort_values(by=['target']).tail(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot pairs correlations\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\ng = sns.pairplot(train_df_new, vars = ['target','ASL','ASW','ROP','RDC','ROS'], diag_kind=\"kde\")\ng.map_lower(sns.kdeplot, levels=4, color=\".2\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ususally low target (= high complex readability score) has longer words, but some excerpts has relatively short words (low ROP),\n# but those words are considered complex (with high ROS, RDC).\n\nlen(train_df_new[(train_df_new['ROP']<0.05) & (train_df_new['target']<-2.5)])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for excerpt in train_df_new[(train_df_new['ROP']<0.05) & (train_df_new['target']<-2.5)]['excerpt']:\n    print (excerpt)\n    print ('--------')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}